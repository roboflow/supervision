{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome","title":"\ud83d\udc4b Welcome","text":"<p>Supervision is a set of easy-to-use utilities that will come in handy in any computer vision project. </p> <p>Supervision is still in  pre-release stage \ud83d\udea7 Keep your eyes open for potential bugs and be aware that at this stage our API is still fluid and may change.</p>"},{"location":"#how-to-install","title":"\ud83d\udcbb How to Install","text":"<p>You can install <code>supervision</code> with pip in a  3.10&gt;=Python&gt;=3.7 environment.</p> <p>Pip install method (recommended)</p> <pre><code>pip install supervision\n</code></pre> <p>Git clone method (for development)</p> <p><pre><code>git https://github.com/roboflow/supervision.git\ncd supervision\npip install -e '.[dev]'\n</code></pre> See contributing section to know more about contributing to the project</p>"},{"location":"detection_core/","title":"Core","text":""},{"location":"detection_core/#detections","title":"Detections","text":"<p>Data class containing information about the detections in a video frame.</p> <p>Attributes:</p> Name Type Description <code>xyxy</code> <code>ndarray</code> <p>An array of shape <code>(n, 4)</code> containing the bounding boxes coordinates in format <code>[x1, y1, x2, y2]</code></p> <code>confidence</code> <code>Optional[ndarray]</code> <p>An array of shape <code>(n,)</code> containing the confidence scores of the detections.</p> <code>class_id</code> <code>ndarray</code> <p>An array of shape <code>(n,)</code> containing the class ids of the detections.</p> <code>tracker_id</code> <code>Optional[ndarray]</code> <p>An array of shape <code>(n,)</code> containing the tracker ids of the detections.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>@dataclass\nclass Detections:\n    \"\"\"\n    Data class containing information about the detections in a video frame.\n\n    Attributes:\n        xyxy (np.ndarray): An array of shape `(n, 4)` containing the bounding boxes coordinates in format `[x1, y1, x2, y2]`\n        confidence (Optional[np.ndarray]): An array of shape `(n,)` containing the confidence scores of the detections.\n        class_id (np.ndarray): An array of shape `(n,)` containing the class ids of the detections.\n        tracker_id (Optional[np.ndarray]): An array of shape `(n,)` containing the tracker ids of the detections.\n    \"\"\"\n\n    xyxy: np.ndarray\n    class_id: np.ndarray\n    confidence: Optional[np.ndarray] = None\n    tracker_id: Optional[np.ndarray] = None\n\n    def __post_init__(self):\n        n = len(self.xyxy)\n        validators = [\n            (isinstance(self.xyxy, np.ndarray) and self.xyxy.shape == (n, 4)),\n            (isinstance(self.class_id, np.ndarray) and self.class_id.shape == (n,)),\n            self.confidence is None\n            or (\n                isinstance(self.confidence, np.ndarray)\n                and self.confidence.shape == (n,)\n            ),\n            self.tracker_id is None\n            or (\n                isinstance(self.tracker_id, np.ndarray)\n                and self.tracker_id.shape == (n,)\n            ),\n        ]\n        if not all(validators):\n            raise ValueError(\n                \"xyxy must be 2d np.ndarray with (n, 4) shape, \"\n                \"confidence must be None or 1d np.ndarray with (n,) shape, \"\n                \"class_id must be 1d np.ndarray with (n,) shape, \"\n                \"tracker_id must be None or 1d np.ndarray with (n,) shape\"\n            )\n\n    def __len__(self):\n        \"\"\"\n        Returns the number of detections in the Detections object.\n        \"\"\"\n        return len(self.xyxy)\n\n    def __iter__(\n        self,\n    ) -&gt; Iterator[Tuple[np.ndarray, Optional[float], int, Optional[Union[str, int]]]]:\n        \"\"\"\n        Iterates over the Detections object and yield a tuple of `(xyxy, confidence, class_id, tracker_id)` for each detection.\n        \"\"\"\n        for i in range(len(self.xyxy)):\n            yield (\n                self.xyxy[i],\n                self.confidence[i] if self.confidence is not None else None,\n                self.class_id[i],\n                self.tracker_id[i] if self.tracker_id is not None else None,\n            )\n\n    def __eq__(self, other: Detections):\n        return all(\n            [\n                np.array_equal(self.xyxy, other.xyxy),\n                any(\n                    [\n                        self.confidence is None and other.confidence is None,\n                        np.array_equal(self.confidence, other.confidence),\n                    ]\n                ),\n                np.array_equal(self.class_id, other.class_id),\n                any(\n                    [\n                        self.tracker_id is None and other.tracker_id is None,\n                        np.array_equal(self.tracker_id, other.tracker_id),\n                    ]\n                ),\n            ]\n        )\n\n    @classmethod\n    def from_yolov5(cls, yolov5_results) -&gt; Detections:\n        \"\"\"\n        Creates a Detections instance from a YOLOv5 output Detections\n\n        Args:\n            yolov5_results (yolov5.models.common.Detections): The output Detections instance from YOLOv5\n\n        Returns:\n            Detections: A new Detections object.\n\n        Example:\n            ```python\n            &gt;&gt;&gt; import torch\n            &gt;&gt;&gt; from supervision import Detections\n\n            &gt;&gt;&gt; model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n            &gt;&gt;&gt; results = model(frame)\n            &gt;&gt;&gt; detections = Detections.from_yolov5(results)\n            ```\n        \"\"\"\n        yolov5_detections_predictions = yolov5_results.pred[0].cpu().cpu().numpy()\n        return cls(\n            xyxy=yolov5_detections_predictions[:, :4],\n            confidence=yolov5_detections_predictions[:, 4],\n            class_id=yolov5_detections_predictions[:, 5].astype(int),\n        )\n\n    @classmethod\n    def from_yolov8(cls, yolov8_results) -&gt; Detections:\n        \"\"\"\n        Creates a Detections instance from a YOLOv8 output Results\n\n        Args:\n            yolov8_results (ultralytics.yolo.engine.results.Results): The output Results instance from YOLOv8\n\n        Returns:\n            Detections: A new Detections object.\n\n        Example:\n            ```python\n            &gt;&gt;&gt; from ultralytics import YOLO\n            &gt;&gt;&gt; from supervision import Detections\n\n            &gt;&gt;&gt; model = YOLO('yolov8s.pt')\n            &gt;&gt;&gt; results = model(frame)[0]\n            &gt;&gt;&gt; detections = Detections.from_yolov8(results)\n            ```\n        \"\"\"\n        return cls(\n            xyxy=yolov8_results.boxes.xyxy.cpu().numpy(),\n            confidence=yolov8_results.boxes.conf.cpu().numpy(),\n            class_id=yolov8_results.boxes.cls.cpu().numpy().astype(int),\n        )\n\n    @classmethod\n    def from_transformers(cls, transformers_results: dict) -&gt; Detections:\n        \"\"\"\n        Creates a Detections instance from Object Detection Transformer output Results\n\n        Returns:\n            Detections: A new Detections object.\n        \"\"\"\n        return cls(\n            xyxy=transformers_results[\"boxes\"].cpu().numpy(),\n            confidence=transformers_results[\"scores\"].cpu().numpy(),\n            class_id=transformers_results[\"labels\"].cpu().numpy().astype(int),\n        )\n\n    @classmethod\n    def from_detectron2(cls, detectron2_results) -&gt; Detections:\n        return cls(\n            xyxy=detectron2_results[\"instances\"].pred_boxes.tensor.cpu().numpy(),\n            confidence=detectron2_results[\"instances\"].scores.cpu().numpy(),\n            class_id=detectron2_results[\"instances\"]\n            .pred_classes.cpu()\n            .numpy()\n            .astype(int),\n        )\n\n    @classmethod\n    def from_coco_annotations(cls, coco_annotation: dict) -&gt; Detections:\n        xyxy, class_id = [], []\n\n        for annotation in coco_annotation:\n            x_min, y_min, width, height = annotation[\"bbox\"]\n            xyxy.append([x_min, y_min, x_min + width, y_min + height])\n            class_id.append(annotation[\"category_id\"])\n\n        return cls(xyxy=np.array(xyxy), class_id=np.array(class_id))\n\n    def get_anchor_coordinates(self, anchor: Position) -&gt; np.ndarray:\n        \"\"\"\n        Returns the bounding box coordinates for a specific anchor.\n\n        Args:\n            anchor (Position): Position of bounding box anchor for which to return the coordinates.\n\n        Returns:\n            np.ndarray: An array of shape `(n, 2)` containing the bounding box anchor coordinates in format `[x, y]`.\n        \"\"\"\n        if anchor == Position.CENTER:\n            return np.array(\n                [\n                    (self.xyxy[:, 0] + self.xyxy[:, 2]) / 2,\n                    (self.xyxy[:, 1] + self.xyxy[:, 3]) / 2,\n                ]\n            ).transpose()\n        elif anchor == Position.BOTTOM_CENTER:\n            return np.array(\n                [(self.xyxy[:, 0] + self.xyxy[:, 2]) / 2, self.xyxy[:, 3]]\n            ).transpose()\n\n        raise ValueError(f\"{anchor} is not supported.\")\n\n    def __getitem__(self, index: np.ndarray) -&gt; Detections:\n        if isinstance(index, np.ndarray) and (\n            index.dtype == bool or index.dtype == int\n        ):\n            return Detections(\n                xyxy=self.xyxy[index],\n                confidence=self.confidence[index],\n                class_id=self.class_id[index],\n                tracker_id=self.tracker_id[index]\n                if self.tracker_id is not None\n                else None,\n            )\n        raise TypeError(\n            f\"Detections.__getitem__ not supported for index of type {type(index)}.\"\n        )\n\n    @property\n    def area(self) -&gt; np.ndarray:\n        \"\"\"\n        Calculate the area of each bounding box in the set of object detections.\n\n        Returns:\n            np.ndarray: An array of floats containing the area of each bounding box in the format of (area_1, area_2, ..., area_n), where n is the number of detections.\n        \"\"\"\n        return (self.xyxy[:, 3] - self.xyxy[:, 1]) * (self.xyxy[:, 2] - self.xyxy[:, 0])\n\n    def with_nms(\n        self, threshold: float = 0.5, class_agnostic: bool = False\n    ) -&gt; Detections:\n        \"\"\"\n        Perform non-maximum suppression on the current set of object detections.\n\n        Args:\n            threshold (float, optional): The intersection-over-union threshold to use for non-maximum suppression. Defaults to 0.5.\n            class_agnostic (bool, optional): Whether to perform class-agnostic non-maximum suppression. If True, the class_id of each detection will be ignored. Defaults to False.\n\n        Returns:\n            Detections: A new Detections object containing the subset of detections after non-maximum suppression.\n\n        Raises:\n            AssertionError: If `confidence` is None and class_agnostic is False. If `class_id` is None and class_agnostic is False.\n        \"\"\"\n        if len(self) == 0:\n            return self\n\n        assert (\n            self.confidence is not None\n        ), f\"Detections confidence must be given for NMS to be executed.\"\n\n        if class_agnostic:\n            predictions = np.hstack((self.xyxy, self.confidence.reshape(-1, 1)))\n            indices = non_max_suppression(\n                predictions=predictions, iou_threshold=threshold\n            )\n            return self[indices]\n\n        assert self.class_id is not None, (\n            f\"Detections class_id must be given for NMS to be executed. If you intended to perform class agnostic \"\n            f\"NMS set class_agnostic=True.\"\n        )\n\n        predictions = np.hstack(\n            (self.xyxy, self.confidence.reshape(-1, 1), self.class_id.reshape(-1, 1))\n        )\n        indices = non_max_suppression(predictions=predictions, iou_threshold=threshold)\n        return self[indices]\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.area","title":"<code>area: np.ndarray</code>  <code>property</code>","text":"<p>Calculate the area of each bounding box in the set of object detections.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: An array of floats containing the area of each bounding box in the format of (area_1, area_2, ..., area_n), where n is the number of detections.</p>"},{"location":"detection_core/#supervision.detection.core.Detections.__iter__","title":"<code>__iter__()</code>","text":"<p>Iterates over the Detections object and yield a tuple of <code>(xyxy, confidence, class_id, tracker_id)</code> for each detection.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>def __iter__(\n    self,\n) -&gt; Iterator[Tuple[np.ndarray, Optional[float], int, Optional[Union[str, int]]]]:\n    \"\"\"\n    Iterates over the Detections object and yield a tuple of `(xyxy, confidence, class_id, tracker_id)` for each detection.\n    \"\"\"\n    for i in range(len(self.xyxy)):\n        yield (\n            self.xyxy[i],\n            self.confidence[i] if self.confidence is not None else None,\n            self.class_id[i],\n            self.tracker_id[i] if self.tracker_id is not None else None,\n        )\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of detections in the Detections object.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>def __len__(self):\n    \"\"\"\n    Returns the number of detections in the Detections object.\n    \"\"\"\n    return len(self.xyxy)\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.from_transformers","title":"<code>from_transformers(transformers_results)</code>  <code>classmethod</code>","text":"<p>Creates a Detections instance from Object Detection Transformer output Results</p> <p>Returns:</p> Name Type Description <code>Detections</code> <code>Detections</code> <p>A new Detections object.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>@classmethod\ndef from_transformers(cls, transformers_results: dict) -&gt; Detections:\n    \"\"\"\n    Creates a Detections instance from Object Detection Transformer output Results\n\n    Returns:\n        Detections: A new Detections object.\n    \"\"\"\n    return cls(\n        xyxy=transformers_results[\"boxes\"].cpu().numpy(),\n        confidence=transformers_results[\"scores\"].cpu().numpy(),\n        class_id=transformers_results[\"labels\"].cpu().numpy().astype(int),\n    )\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.from_yolov5","title":"<code>from_yolov5(yolov5_results)</code>  <code>classmethod</code>","text":"<p>Creates a Detections instance from a YOLOv5 output Detections</p> <p>Parameters:</p> Name Type Description Default <code>yolov5_results</code> <code>Detections</code> <p>The output Detections instance from YOLOv5</p> required <p>Returns:</p> Name Type Description <code>Detections</code> <code>Detections</code> <p>A new Detections object.</p> Example <pre><code>&gt;&gt;&gt; import torch\n&gt;&gt;&gt; from supervision import Detections\n\n&gt;&gt;&gt; model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n&gt;&gt;&gt; results = model(frame)\n&gt;&gt;&gt; detections = Detections.from_yolov5(results)\n</code></pre> Source code in <code>supervision/detection/core.py</code> <pre><code>@classmethod\ndef from_yolov5(cls, yolov5_results) -&gt; Detections:\n    \"\"\"\n    Creates a Detections instance from a YOLOv5 output Detections\n\n    Args:\n        yolov5_results (yolov5.models.common.Detections): The output Detections instance from YOLOv5\n\n    Returns:\n        Detections: A new Detections object.\n\n    Example:\n        ```python\n        &gt;&gt;&gt; import torch\n        &gt;&gt;&gt; from supervision import Detections\n\n        &gt;&gt;&gt; model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n        &gt;&gt;&gt; results = model(frame)\n        &gt;&gt;&gt; detections = Detections.from_yolov5(results)\n        ```\n    \"\"\"\n    yolov5_detections_predictions = yolov5_results.pred[0].cpu().cpu().numpy()\n    return cls(\n        xyxy=yolov5_detections_predictions[:, :4],\n        confidence=yolov5_detections_predictions[:, 4],\n        class_id=yolov5_detections_predictions[:, 5].astype(int),\n    )\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.from_yolov8","title":"<code>from_yolov8(yolov8_results)</code>  <code>classmethod</code>","text":"<p>Creates a Detections instance from a YOLOv8 output Results</p> <p>Parameters:</p> Name Type Description Default <code>yolov8_results</code> <code>Results</code> <p>The output Results instance from YOLOv8</p> required <p>Returns:</p> Name Type Description <code>Detections</code> <code>Detections</code> <p>A new Detections object.</p> Example <pre><code>&gt;&gt;&gt; from ultralytics import YOLO\n&gt;&gt;&gt; from supervision import Detections\n\n&gt;&gt;&gt; model = YOLO('yolov8s.pt')\n&gt;&gt;&gt; results = model(frame)[0]\n&gt;&gt;&gt; detections = Detections.from_yolov8(results)\n</code></pre> Source code in <code>supervision/detection/core.py</code> <pre><code>@classmethod\ndef from_yolov8(cls, yolov8_results) -&gt; Detections:\n    \"\"\"\n    Creates a Detections instance from a YOLOv8 output Results\n\n    Args:\n        yolov8_results (ultralytics.yolo.engine.results.Results): The output Results instance from YOLOv8\n\n    Returns:\n        Detections: A new Detections object.\n\n    Example:\n        ```python\n        &gt;&gt;&gt; from ultralytics import YOLO\n        &gt;&gt;&gt; from supervision import Detections\n\n        &gt;&gt;&gt; model = YOLO('yolov8s.pt')\n        &gt;&gt;&gt; results = model(frame)[0]\n        &gt;&gt;&gt; detections = Detections.from_yolov8(results)\n        ```\n    \"\"\"\n    return cls(\n        xyxy=yolov8_results.boxes.xyxy.cpu().numpy(),\n        confidence=yolov8_results.boxes.conf.cpu().numpy(),\n        class_id=yolov8_results.boxes.cls.cpu().numpy().astype(int),\n    )\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.get_anchor_coordinates","title":"<code>get_anchor_coordinates(anchor)</code>","text":"<p>Returns the bounding box coordinates for a specific anchor.</p> <p>Parameters:</p> Name Type Description Default <code>anchor</code> <code>Position</code> <p>Position of bounding box anchor for which to return the coordinates.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: An array of shape <code>(n, 2)</code> containing the bounding box anchor coordinates in format <code>[x, y]</code>.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>def get_anchor_coordinates(self, anchor: Position) -&gt; np.ndarray:\n    \"\"\"\n    Returns the bounding box coordinates for a specific anchor.\n\n    Args:\n        anchor (Position): Position of bounding box anchor for which to return the coordinates.\n\n    Returns:\n        np.ndarray: An array of shape `(n, 2)` containing the bounding box anchor coordinates in format `[x, y]`.\n    \"\"\"\n    if anchor == Position.CENTER:\n        return np.array(\n            [\n                (self.xyxy[:, 0] + self.xyxy[:, 2]) / 2,\n                (self.xyxy[:, 1] + self.xyxy[:, 3]) / 2,\n            ]\n        ).transpose()\n    elif anchor == Position.BOTTOM_CENTER:\n        return np.array(\n            [(self.xyxy[:, 0] + self.xyxy[:, 2]) / 2, self.xyxy[:, 3]]\n        ).transpose()\n\n    raise ValueError(f\"{anchor} is not supported.\")\n</code></pre>"},{"location":"detection_core/#supervision.detection.core.Detections.with_nms","title":"<code>with_nms(threshold=0.5, class_agnostic=False)</code>","text":"<p>Perform non-maximum suppression on the current set of object detections.</p> <p>Parameters:</p> Name Type Description Default <code>threshold</code> <code>float</code> <p>The intersection-over-union threshold to use for non-maximum suppression. Defaults to 0.5.</p> <code>0.5</code> <code>class_agnostic</code> <code>bool</code> <p>Whether to perform class-agnostic non-maximum suppression. If True, the class_id of each detection will be ignored. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Detections</code> <code>Detections</code> <p>A new Detections object containing the subset of detections after non-maximum suppression.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If <code>confidence</code> is None and class_agnostic is False. If <code>class_id</code> is None and class_agnostic is False.</p> Source code in <code>supervision/detection/core.py</code> <pre><code>def with_nms(\n    self, threshold: float = 0.5, class_agnostic: bool = False\n) -&gt; Detections:\n    \"\"\"\n    Perform non-maximum suppression on the current set of object detections.\n\n    Args:\n        threshold (float, optional): The intersection-over-union threshold to use for non-maximum suppression. Defaults to 0.5.\n        class_agnostic (bool, optional): Whether to perform class-agnostic non-maximum suppression. If True, the class_id of each detection will be ignored. Defaults to False.\n\n    Returns:\n        Detections: A new Detections object containing the subset of detections after non-maximum suppression.\n\n    Raises:\n        AssertionError: If `confidence` is None and class_agnostic is False. If `class_id` is None and class_agnostic is False.\n    \"\"\"\n    if len(self) == 0:\n        return self\n\n    assert (\n        self.confidence is not None\n    ), f\"Detections confidence must be given for NMS to be executed.\"\n\n    if class_agnostic:\n        predictions = np.hstack((self.xyxy, self.confidence.reshape(-1, 1)))\n        indices = non_max_suppression(\n            predictions=predictions, iou_threshold=threshold\n        )\n        return self[indices]\n\n    assert self.class_id is not None, (\n        f\"Detections class_id must be given for NMS to be executed. If you intended to perform class agnostic \"\n        f\"NMS set class_agnostic=True.\"\n    )\n\n    predictions = np.hstack(\n        (self.xyxy, self.confidence.reshape(-1, 1), self.class_id.reshape(-1, 1))\n    )\n    indices = non_max_suppression(predictions=predictions, iou_threshold=threshold)\n    return self[indices]\n</code></pre>"},{"location":"detection_utils/","title":"Utils","text":""},{"location":"detection_utils/#generate_2d_mask","title":"generate_2d_mask","text":"<p>Generate a 2D mask from a polygon.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>ndarray</code> <p>The polygon for which the mask should be generated, given as a list of vertices.</p> required <code>resolution_wh</code> <code>Tuple[int, int]</code> <p>The width and height of the desired resolution.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The generated 2D mask, where the polygon is marked with <code>1</code>'s and the rest is filled with <code>0</code>'s.</p> Source code in <code>supervision/detection/utils.py</code> <pre><code>def generate_2d_mask(polygon: np.ndarray, resolution_wh: Tuple[int, int]) -&gt; np.ndarray:\n    \"\"\"Generate a 2D mask from a polygon.\n\n    Args:\n        polygon (np.ndarray): The polygon for which the mask should be generated, given as a list of vertices.\n        resolution_wh (Tuple[int, int]): The width and height of the desired resolution.\n\n    Returns:\n        np.ndarray: The generated 2D mask, where the polygon is marked with `1`'s and the rest is filled with `0`'s.\n    \"\"\"\n    width, height = resolution_wh\n    mask = np.zeros((height, width), dtype=np.uint8)\n    cv2.fillPoly(mask, [polygon], color=1)\n    return mask\n</code></pre>"},{"location":"detection_utils/#box_iou_batch","title":"box_iou_batch","text":"<p>Compute Intersection over Union (IoU) of two sets of bounding boxes - <code>boxes_true</code> and <code>boxes_detection</code>. Both sets of boxes are expected to be in <code>(x_min, y_min, x_max, y_max)</code> format.</p> <p>Parameters:</p> Name Type Description Default <code>boxes_true</code> <code>ndarray</code> <p>2D <code>np.ndarray</code> representing ground-truth boxes. <code>shape = (N, 4)</code> where <code>N</code> is number of true objects.</p> required <code>boxes_detection</code> <code>ndarray</code> <p>2D <code>np.ndarray</code> representing detection boxes. <code>shape = (M, 4)</code> where <code>M</code> is number of detected objects.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Pairwise IoU of boxes from <code>boxes_true</code> and <code>boxes_detection</code>. <code>shape = (N, M)</code> where <code>N</code> is number of true objects and <code>M</code> is number of detected objects.</p> Source code in <code>supervision/detection/utils.py</code> <pre><code>def box_iou_batch(boxes_true: np.ndarray, boxes_detection: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Compute Intersection over Union (IoU) of two sets of bounding boxes - `boxes_true` and `boxes_detection`. Both sets\n    of boxes are expected to be in `(x_min, y_min, x_max, y_max)` format.\n\n    Args:\n        boxes_true (np.ndarray): 2D `np.ndarray` representing ground-truth boxes. `shape = (N, 4)` where `N` is number of true objects.\n        boxes_detection (np.ndarray): 2D `np.ndarray` representing detection boxes. `shape = (M, 4)` where `M` is number of detected objects.\n\n    Returns:\n        np.ndarray: Pairwise IoU of boxes from `boxes_true` and `boxes_detection`. `shape = (N, M)` where `N` is number of true objects and `M` is number of detected objects.\n    \"\"\"\n\n    def box_area(box):\n        return (box[2] - box[0]) * (box[3] - box[1])\n\n    area_true = box_area(boxes_true.T)\n    area_detection = box_area(boxes_detection.T)\n\n    top_left = np.maximum(boxes_true[:, None, :2], boxes_detection[:, :2])\n    bottom_right = np.minimum(boxes_true[:, None, 2:], boxes_detection[:, 2:])\n\n    area_inter = np.prod(np.clip(bottom_right - top_left, a_min=0, a_max=None), 2)\n    return area_inter / (area_true[:, None] + area_detection - area_inter)\n</code></pre>"},{"location":"detection_utils/#non_max_suppression","title":"non_max_suppression","text":"<p>Perform Non-Maximum Suppression (NMS) on object detection predictions.</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>ndarray</code> <p>An array of object detection predictions in the format of <code>(x_min, y_min, x_max, y_max, score)</code> or <code>(x_min, y_min, x_max, y_max, score, class)</code>.</p> required <code>iou_threshold</code> <code>float</code> <p>The intersection-over-union threshold to use for non-maximum suppression.</p> <code>0.5</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A boolean array indicating which predictions to keep after non-maximum suppression.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If <code>iou_threshold</code> is not within the closed range from <code>0</code> to <code>1</code>.</p> Source code in <code>supervision/detection/utils.py</code> <pre><code>def non_max_suppression(\n    predictions: np.ndarray, iou_threshold: float = 0.5\n) -&gt; np.ndarray:\n    \"\"\"\n    Perform Non-Maximum Suppression (NMS) on object detection predictions.\n\n    Args:\n        predictions (np.ndarray): An array of object detection predictions in the format of `(x_min, y_min, x_max, y_max, score)` or `(x_min, y_min, x_max, y_max, score, class)`.\n        iou_threshold (float, optional): The intersection-over-union threshold to use for non-maximum suppression.\n\n    Returns:\n        np.ndarray: A boolean array indicating which predictions to keep after non-maximum suppression.\n\n    Raises:\n        AssertionError: If `iou_threshold` is not within the closed range from `0` to `1`.\n    \"\"\"\n    assert 0 &lt;= iou_threshold &lt;= 1, (\n        f\"Value of `iou_threshold` must be in the closed range from 0 to 1, \"\n        f\"{iou_threshold} given.\"\n    )\n    rows, columns = predictions.shape\n\n    # add column #5 - category filled with zeros for agnostic nms\n    if columns == 5:\n        predictions = np.c_[predictions, np.zeros(rows)]\n\n    # sort predictions column #4 - score\n    sort_index = np.flip(predictions[:, 4].argsort())\n    predictions = predictions[sort_index]\n\n    boxes = predictions[:, :4]\n    categories = predictions[:, 5]\n    ious = box_iou_batch(boxes, boxes)\n    ious = ious - np.eye(rows)\n\n    keep = np.ones(rows, dtype=bool)\n\n    for index, (iou, category) in enumerate(zip(ious, categories)):\n        if not keep[index]:\n            continue\n\n        # drop detections with iou &gt; iou_threshold and same category as current detections\n        condition = (iou &gt; iou_threshold) &amp; (categories == category)\n        keep = keep &amp; ~condition\n\n    return keep[sort_index.argsort()]\n</code></pre>"},{"location":"draw_utils/","title":"Utils","text":""},{"location":"draw_utils/#draw_line","title":"draw_line","text":"<p>Draws a line on a given scene.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>ndarray</code> <p>The scene on which the line will be drawn</p> required <code>start</code> <code>Point</code> <p>The starting point of the line</p> required <code>end</code> <code>Point</code> <p>The end point of the line</p> required <code>color</code> <code>Color</code> <p>The color of the line</p> required <code>thickness</code> <code>int</code> <p>The thickness of the line</p> <code>2</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The scene with the line drawn on it</p> Source code in <code>supervision/draw/utils.py</code> <pre><code>def draw_line(\n    scene: np.ndarray, start: Point, end: Point, color: Color, thickness: int = 2\n) -&gt; np.ndarray:\n    \"\"\"\n    Draws a line on a given scene.\n\n    Parameters:\n        scene (np.ndarray): The scene on which the line will be drawn\n        start (Point): The starting point of the line\n        end (Point): The end point of the line\n        color (Color): The color of the line\n        thickness (int): The thickness of the line\n\n    Returns:\n        np.ndarray: The scene with the line drawn on it\n    \"\"\"\n    cv2.line(\n        scene,\n        start.as_xy_int_tuple(),\n        end.as_xy_int_tuple(),\n        color.as_bgr(),\n        thickness=thickness,\n    )\n    return scene\n</code></pre>"},{"location":"draw_utils/#draw_rectangle","title":"draw_rectangle","text":"<p>Draws a rectangle on an image.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>ndarray</code> <p>The scene on which the rectangle will be drawn</p> required <code>rect</code> <code>Rect</code> <p>The rectangle to be drawn</p> required <code>color</code> <code>Color</code> <p>The color of the rectangle</p> required <code>thickness</code> <code>int</code> <p>The thickness of the rectangle border</p> <code>2</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The scene with the rectangle drawn on it</p> Source code in <code>supervision/draw/utils.py</code> <pre><code>def draw_rectangle(\n    scene: np.ndarray, rect: Rect, color: Color, thickness: int = 2\n) -&gt; np.ndarray:\n    \"\"\"\n    Draws a rectangle on an image.\n\n    Parameters:\n        scene (np.ndarray): The scene on which the rectangle will be drawn\n        rect (Rect): The rectangle to be drawn\n        color (Color): The color of the rectangle\n        thickness (int): The thickness of the rectangle border\n\n    Returns:\n        np.ndarray: The scene with the rectangle drawn on it\n    \"\"\"\n    cv2.rectangle(\n        scene,\n        rect.top_left.as_xy_int_tuple(),\n        rect.bottom_right.as_xy_int_tuple(),\n        color.as_bgr(),\n        thickness=thickness,\n    )\n    return scene\n</code></pre>"},{"location":"draw_utils/#draw_filled_rectangle","title":"draw_filled_rectangle","text":"<p>Draws a filled rectangle on an image.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>ndarray</code> <p>The scene on which the rectangle will be drawn</p> required <code>rect</code> <code>Rect</code> <p>The rectangle to be drawn</p> required <code>color</code> <code>Color</code> <p>The color of the rectangle</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The scene with the rectangle drawn on it</p> Source code in <code>supervision/draw/utils.py</code> <pre><code>def draw_filled_rectangle(scene: np.ndarray, rect: Rect, color: Color) -&gt; np.ndarray:\n    \"\"\"\n    Draws a filled rectangle on an image.\n\n    Parameters:\n        scene (np.ndarray): The scene on which the rectangle will be drawn\n        rect (Rect): The rectangle to be drawn\n        color (Color): The color of the rectangle\n\n    Returns:\n        np.ndarray: The scene with the rectangle drawn on it\n    \"\"\"\n    cv2.rectangle(\n        scene,\n        rect.top_left.as_xy_int_tuple(),\n        rect.bottom_right.as_xy_int_tuple(),\n        color.as_bgr(),\n        -1,\n    )\n    return scene\n</code></pre>"},{"location":"draw_utils/#draw_polygon","title":"draw_polygon","text":"<p>Draw a polygon on a scene.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>ndarray</code> <p>The scene to draw the polygon on.</p> required <code>polygon</code> <code>ndarray</code> <p>The polygon to be drawn, given as a list of vertices.</p> required <code>color</code> <code>Color</code> <p>The color of the polygon.</p> required <code>thickness</code> <code>int</code> <p>The thickness of the polygon lines, by default 2.</p> <code>2</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The scene with the polygon drawn on it.</p> Source code in <code>supervision/draw/utils.py</code> <pre><code>def draw_polygon(\n    scene: np.ndarray, polygon: np.ndarray, color: Color, thickness: int = 2\n) -&gt; np.ndarray:\n    \"\"\"Draw a polygon on a scene.\n\n    Parameters:\n        scene (np.ndarray): The scene to draw the polygon on.\n        polygon (np.ndarray): The polygon to be drawn, given as a list of vertices.\n        color (Color): The color of the polygon.\n        thickness (int, optional): The thickness of the polygon lines, by default 2.\n\n    Returns:\n        np.ndarray: The scene with the polygon drawn on it.\n    \"\"\"\n    cv2.polylines(\n        scene, [polygon], isClosed=True, color=color.as_bgr(), thickness=thickness\n    )\n    return scene\n</code></pre>"},{"location":"draw_utils/#draw_text","title":"draw_text","text":"<p>Draw text with background on a scene.</p> <p>Parameters:</p> Name Type Description Default <code>scene</code> <code>ndarray</code> <p>A 2-dimensional numpy ndarray representing an image or scene.</p> required <code>text</code> <code>str</code> <p>The text to be drawn.</p> required <code>text_anchor</code> <code>Point</code> <p>The anchor point for the text, represented as a Point object with x and y attributes.</p> required <code>text_color</code> <code>Color</code> <p>The color of the text. Defaults to black.</p> <code>black()</code> <code>text_scale</code> <code>float</code> <p>The scale of the text. Defaults to 0.5.</p> <code>0.5</code> <code>text_thickness</code> <code>int</code> <p>The thickness of the text. Defaults to 1.</p> <code>1</code> <code>text_padding</code> <code>int</code> <p>The amount of padding to add around the text when drawing a rectangle in the background. Defaults to 10.</p> <code>10</code> <code>text_font</code> <code>int</code> <p>The font to use for the text. Defaults to cv2.FONT_HERSHEY_SIMPLEX.</p> <code>FONT_HERSHEY_SIMPLEX</code> <code>background_color</code> <code>Color</code> <p>The color of the background rectangle, if one is to be drawn. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The input scene with the text drawn on it.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; scene = np.zeros((100, 100, 3), dtype=np.uint8)\n&gt;&gt;&gt; text_anchor = Point(x=50, y=50)\n&gt;&gt;&gt; scene = draw_text(scene=scene, text=\"Hello, world!\", text_anchor=text_anchor)\n</code></pre> Source code in <code>supervision/draw/utils.py</code> <pre><code>def draw_text(\n    scene: np.ndarray,\n    text: str,\n    text_anchor: Point,\n    text_color: Color = Color.black(),\n    text_scale: float = 0.5,\n    text_thickness: int = 1,\n    text_padding: int = 10,\n    text_font: int = cv2.FONT_HERSHEY_SIMPLEX,\n    background_color: Optional[Color] = None,\n) -&gt; np.ndarray:\n    \"\"\"\n    Draw text with background on a scene.\n\n    Parameters:\n        scene (np.ndarray): A 2-dimensional numpy ndarray representing an image or scene.\n        text (str): The text to be drawn.\n        text_anchor (Point): The anchor point for the text, represented as a Point object with x and y attributes.\n        text_color (Color, optional): The color of the text. Defaults to black.\n        text_scale (float, optional): The scale of the text. Defaults to 0.5.\n        text_thickness (int, optional): The thickness of the text. Defaults to 1.\n        text_padding (int, optional): The amount of padding to add around the text when drawing a rectangle in the background. Defaults to 10.\n        text_font (int, optional): The font to use for the text. Defaults to cv2.FONT_HERSHEY_SIMPLEX.\n        background_color (Color, optional): The color of the background rectangle, if one is to be drawn. Defaults to None.\n\n    Returns:\n        np.ndarray: The input scene with the text drawn on it.\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; scene = np.zeros((100, 100, 3), dtype=np.uint8)\n        &gt;&gt;&gt; text_anchor = Point(x=50, y=50)\n        &gt;&gt;&gt; scene = draw_text(scene=scene, text=\"Hello, world!\", text_anchor=text_anchor)\n        ```\n    \"\"\"\n    text_width, text_height = cv2.getTextSize(\n        text=text,\n        fontFace=text_font,\n        fontScale=text_scale,\n        thickness=text_thickness,\n    )[0]\n    text_rect = Rect(\n        x=text_anchor.x - text_width // 2,\n        y=text_anchor.y - text_height // 2,\n        width=text_width,\n        height=text_height,\n    ).pad(text_padding)\n\n    if background_color is not None:\n        scene = draw_filled_rectangle(\n            scene=scene, rect=text_rect, color=background_color\n        )\n\n    cv2.putText(\n        img=scene,\n        text=text,\n        org=(text_anchor.x - text_width // 2, text_anchor.y + text_height // 2),\n        fontFace=text_font,\n        fontScale=text_scale,\n        color=text_color.as_bgr(),\n        thickness=text_thickness,\n        lineType=cv2.LINE_AA,\n    )\n    return scene\n</code></pre>"},{"location":"notebook/","title":"Notebook","text":""},{"location":"notebook/#show_frame_in_notebook","title":"show_frame_in_notebook","text":"<p>Display a frame in Jupyter Notebook using Matplotlib</p> <p>Attributes:</p> Name Type Description <code>frame</code> <code>ndarray</code> <p>The frame to be displayed.</p> <code>size</code> <code>Tuple[int, int]</code> <p>The size of the plot. default:(10,10)</p> <code>cmap</code> <code>str</code> <p>the colormap to use for single channel images. default:gray</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision.notebook.utils import show_frame_in_notebook\n\n%matplotlib inline\nshow_frame_in_notebook(frame, (16, 16))\n</code></pre> Source code in <code>supervision/notebook/utils.py</code> <pre><code>def show_frame_in_notebook(\n    frame: np.ndarray, size: Tuple[int, int] = (10, 10), cmap: str = \"gray\"\n):\n    \"\"\"\n    Display a frame in Jupyter Notebook using Matplotlib\n\n    Attributes:\n        frame (np.ndarray): The frame to be displayed.\n        size (Tuple[int, int]): The size of the plot. default:(10,10)\n        cmap (str): the colormap to use for single channel images. default:gray\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision.notebook.utils import show_frame_in_notebook\n\n        %matplotlib inline\n        show_frame_in_notebook(frame, (16, 16))\n        ```\n    \"\"\"\n    if frame.ndim == 2:\n        plt.figure(figsize=size)\n        plt.imshow(frame, cmap=cmap)\n    else:\n        plt.figure(figsize=size)\n        plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n    plt.show()\n</code></pre>"},{"location":"video/","title":"Video","text":""},{"location":"video/#videoinfo","title":"VideoInfo","text":"<p>A class to store video information, including width, height, fps and total number of frames.</p> <p>Attributes:</p> Name Type Description <code>width</code> <code>int</code> <p>width of the video in pixels</p> <code>height</code> <code>int</code> <p>height of the video in pixels</p> <code>fps</code> <code>int</code> <p>frames per second of the video</p> <code>total_frames</code> <code>int</code> <p>total number of frames in the video, default is None</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision import VideoInfo\n\n&gt;&gt;&gt; video_info = VideoInfo.from_video_path(video_path='video.mp4')\n\n&gt;&gt;&gt; video_info\nVideoInfo(width=3840, height=2160, fps=25, total_frames=538)\n\n&gt;&gt;&gt; video_info.resolution_wh\n(3840, 2160)\n</code></pre> Source code in <code>supervision/video.py</code> <pre><code>@dataclass\nclass VideoInfo:\n    \"\"\"\n    A class to store video information, including width, height, fps and total number of frames.\n\n    Attributes:\n        width (int): width of the video in pixels\n        height (int): height of the video in pixels\n        fps (int): frames per second of the video\n        total_frames (int, optional): total number of frames in the video, default is None\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision import VideoInfo\n\n        &gt;&gt;&gt; video_info = VideoInfo.from_video_path(video_path='video.mp4')\n\n        &gt;&gt;&gt; video_info\n        VideoInfo(width=3840, height=2160, fps=25, total_frames=538)\n\n        &gt;&gt;&gt; video_info.resolution_wh\n        (3840, 2160)\n        ```\n    \"\"\"\n\n    width: int\n    height: int\n    fps: int\n    total_frames: Optional[int] = None\n\n    @classmethod\n    def from_video_path(cls, video_path: str) -&gt; VideoInfo:\n        video = cv2.VideoCapture(video_path)\n        if not video.isOpened():\n            raise Exception(f\"Could not open video at {video_path}\")\n\n        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n        fps = int(video.get(cv2.CAP_PROP_FPS))\n        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n        video.release()\n        return VideoInfo(width, height, fps, total_frames)\n\n    @property\n    def resolution_wh(self) -&gt; Tuple[int, int]:\n        return self.width, self.height\n</code></pre>"},{"location":"video/#videosink","title":"VideoSink","text":"<p>Context manager that saves video frames to a file using OpenCV.</p> <p>Attributes:</p> Name Type Description <code>target_path</code> <code>str</code> <p>The path to the output file where the video will be saved.</p> <code>video_info</code> <code>VideoInfo</code> <p>Information about the video resolution, fps, and total frame count.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision import VideoInfo, VideoSink\n\n&gt;&gt;&gt; video_info = VideoInfo.from_video_path(video_path='source_video.mp4')\n\n&gt;&gt;&gt; with VideoSink(target_path='target_video.mp4', video_info=video_info) as s:\n...     frame = ...\n...     s.write_frame(frame=frame)\n</code></pre> Source code in <code>supervision/video.py</code> <pre><code>class VideoSink:\n    \"\"\"\n    Context manager that saves video frames to a file using OpenCV.\n\n    Attributes:\n        target_path (str): The path to the output file where the video will be saved.\n        video_info (VideoInfo): Information about the video resolution, fps, and total frame count.\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision import VideoInfo, VideoSink\n\n        &gt;&gt;&gt; video_info = VideoInfo.from_video_path(video_path='source_video.mp4')\n\n        &gt;&gt;&gt; with VideoSink(target_path='target_video.mp4', video_info=video_info) as s:\n        ...     frame = ...\n        ...     s.write_frame(frame=frame)\n        ```\n    \"\"\"\n\n    def __init__(self, target_path: str, video_info: VideoInfo):\n        self.target_path = target_path\n        self.video_info = video_info\n        self.__fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n        self.__writer = None\n\n    def __enter__(self):\n        self.__writer = cv2.VideoWriter(\n            self.target_path,\n            self.__fourcc,\n            self.video_info.fps,\n            self.video_info.resolution_wh,\n        )\n        return self\n\n    def write_frame(self, frame: np.ndarray):\n        self.__writer.write(frame)\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.__writer.release()\n</code></pre>"},{"location":"video/#get_video_frames_generator","title":"get_video_frames_generator","text":"<p>Get a generator that yields the frames of the video.</p> <p>Parameters:</p> Name Type Description Default <code>source_path</code> <code>str</code> <p>The path of the video file.</p> required <p>Returns:</p> Type Description <code>Generator[ndarray, None, None]</code> <p>A generator that yields the frames of the video.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision import get_video_frames_generator\n\n&gt;&gt;&gt; for frame in get_video_frames_generator(source_path='source_video.mp4'):\n...     ...\n</code></pre> Source code in <code>supervision/video.py</code> <pre><code>def get_video_frames_generator(source_path: str) -&gt; Generator[np.ndarray, None, None]:\n    \"\"\"\n    Get a generator that yields the frames of the video.\n\n    Args:\n        source_path (str): The path of the video file.\n\n    Returns:\n        (Generator[np.ndarray, None, None]): A generator that yields the frames of the video.\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision import get_video_frames_generator\n\n        &gt;&gt;&gt; for frame in get_video_frames_generator(source_path='source_video.mp4'):\n        ...     ...\n        ```\n    \"\"\"\n    video = cv2.VideoCapture(source_path)\n    if not video.isOpened():\n        raise Exception(f\"Could not open video at {source_path}\")\n    success, frame = video.read()\n    while success:\n        yield frame\n        success, frame = video.read()\n    video.release()\n</code></pre>"},{"location":"video/#process_video","title":"process_video","text":"<p>Process a video file by applying a callback function on each frame and saving the result to a target video file.</p> <p>Parameters:</p> Name Type Description Default <code>source_path</code> <code>str</code> <p>The path to the source video file.</p> required <code>target_path</code> <code>str</code> <p>The path to the target video file.</p> required <code>callback</code> <code>Callable[[ndarray, int], ndarray]</code> <p>A function that takes in a numpy ndarray representation of a video frame and an int index of the frame and returns a processed numpy ndarray representation of the frame.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; from supervision import process_video\n\n&gt;&gt;&gt; def process_frame(scene: np.ndarray) -&gt; np.ndarray:\n...     ...\n\n&gt;&gt;&gt; process_video(\n...     source_path='source_video.mp4',\n...     target_path='target_video.mp4',\n...     callback=process_frame\n... )\n</code></pre> Source code in <code>supervision/video.py</code> <pre><code>def process_video(\n    source_path: str,\n    target_path: str,\n    callback: Callable[[np.ndarray, int], np.ndarray],\n) -&gt; None:\n    \"\"\"\n    Process a video file by applying a callback function on each frame and saving the result to a target video file.\n\n    Args:\n        source_path (str): The path to the source video file.\n        target_path (str): The path to the target video file.\n        callback (Callable[[np.ndarray, int], np.ndarray]): A function that takes in a numpy ndarray representation of a video frame and an int index of the frame and returns a processed numpy ndarray representation of the frame.\n\n    Examples:\n        ```python\n        &gt;&gt;&gt; from supervision import process_video\n\n        &gt;&gt;&gt; def process_frame(scene: np.ndarray) -&gt; np.ndarray:\n        ...     ...\n\n        &gt;&gt;&gt; process_video(\n        ...     source_path='source_video.mp4',\n        ...     target_path='target_video.mp4',\n        ...     callback=process_frame\n        ... )\n        ```\n    \"\"\"\n    source_video_info = VideoInfo.from_video_path(video_path=source_path)\n    with VideoSink(target_path=target_path, video_info=source_video_info) as sink:\n        for index, frame in enumerate(\n            get_video_frames_generator(source_path=source_path)\n        ):\n            result_frame = callback(frame, index)\n            sink.write_frame(frame=result_frame)\n</code></pre>"}]}